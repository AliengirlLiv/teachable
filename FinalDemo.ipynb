{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THINGS TO CHECK\n",
    "\n",
    "# HIGH PRIORITY:\n",
    "# - Get Ant working\n",
    "# - Visualize results\n",
    "# - Confirm it actually works\n",
    "# - Figure out if there's a way to run faster\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# - Does it run from scratch on a new computer?\n",
    "# - Add saved buffers/trajs to the real repo\n",
    "# - matplotlib import in test_generalization\n",
    "# - Changes to local version\n",
    "# - envdist location\n",
    "# - recon_coef\n",
    "# - Pixel counts\n",
    "# - Save to a better location\n",
    "\n",
    "# STRETCH\n",
    "# - Setup.py\n",
    "# - If we want to move envdist, then switch to only saving weights or re-collect\n",
    "# - Collect val set\n",
    "# - Hide Code\n",
    "# - Hide unnecessary printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: Not a git repository (or any of the parent directories): .git\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout 61f8cd55488419fb785277e42861e443a57d093d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup - do this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'teachable' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/aliengirlliv/teachable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/olivia/Documents/Teachable/demo/teachable\n"
     ]
    }
   ],
   "source": [
    "cd teachable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Your local changes to the following files would be overwritten by checkout:\n",
      "\talgos/agent.py\n",
      "Please, commit your changes or stash them before you can switch branches.\n",
      "Aborting\n",
      "Requirement already satisfied: scikit-build in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: torch in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 2)) (1.8.1)\n",
      "Requirement already satisfied: opencv-python in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 3)) (4.2.0.32)\n",
      "Requirement already satisfied: gym_minigrid in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: numpy==1.19.5 in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 5)) (1.19.5)\n",
      "Requirement already satisfied: gym==0.18.0 in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 6)) (0.18.0)\n",
      "Requirement already satisfied: matplotlib==2.2.3 in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 7)) (2.2.3)\n",
      "Requirement already satisfied: imageio==2.4.1 in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 8)) (2.4.1)\n",
      "Requirement already satisfied: joblib==0.12.4 in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 9)) (0.12.4)\n",
      "Requirement already satisfied: colorama in /home/olivia/anaconda3/lib/python3.7/site-packages (from -r reqs.txt (line 10)) (0.4.1)\n",
      "Requirement already satisfied: wheel>=0.29.0 in /home/olivia/anaconda3/lib/python3.7/site-packages (from scikit-build->-r reqs.txt (line 1)) (0.36.2)\n",
      "Requirement already satisfied: distro in /home/olivia/anaconda3/lib/python3.7/site-packages (from scikit-build->-r reqs.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: setuptools>=28.0.0; python_version >= \"3\" in /home/olivia/anaconda3/lib/python3.7/site-packages (from scikit-build->-r reqs.txt (line 1)) (41.4.0)\n",
      "Requirement already satisfied: packaging in /home/olivia/anaconda3/lib/python3.7/site-packages (from scikit-build->-r reqs.txt (line 1)) (19.2)\n",
      "Requirement already satisfied: typing-extensions in /home/olivia/anaconda3/lib/python3.7/site-packages (from torch->-r reqs.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: scipy in /home/olivia/anaconda3/lib/python3.7/site-packages (from gym==0.18.0->-r reqs.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/olivia/anaconda3/lib/python3.7/site-packages (from gym==0.18.0->-r reqs.txt (line 6)) (1.6.0)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in /home/olivia/anaconda3/lib/python3.7/site-packages (from gym==0.18.0->-r reqs.txt (line 6)) (6.2.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/olivia/anaconda3/lib/python3.7/site-packages (from gym==0.18.0->-r reqs.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/olivia/anaconda3/lib/python3.7/site-packages (from matplotlib==2.2.3->-r reqs.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/olivia/anaconda3/lib/python3.7/site-packages (from matplotlib==2.2.3->-r reqs.txt (line 7)) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/olivia/anaconda3/lib/python3.7/site-packages (from matplotlib==2.2.3->-r reqs.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: pytz in /home/olivia/anaconda3/lib/python3.7/site-packages (from matplotlib==2.2.3->-r reqs.txt (line 7)) (2019.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/olivia/anaconda3/lib/python3.7/site-packages (from matplotlib==2.2.3->-r reqs.txt (line 7)) (2.4.2)\n",
      "Requirement already satisfied: six>=1.10 in /home/olivia/anaconda3/lib/python3.7/site-packages (from matplotlib==2.2.3->-r reqs.txt (line 7)) (1.15.0)\n",
      "Requirement already satisfied: future in /home/olivia/anaconda3/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.18.0->-r reqs.txt (line 6)) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: REPLACE SAC WITH MAIN\n",
    "!git checkout sac\n",
    "!pip install -r reqs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup - Do this each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'teachable'\n",
      "/home/olivia/Documents/Teachable/demo/teachable\n"
     ]
    }
   ],
   "source": [
    "cd teachable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from importlib import reload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Mujoco-based envs failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'd4rl_content'\n",
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'd4rl_content'\n",
      "Warning: FrankaKitchen failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'd4rl_content'\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'd4rl_content'\n",
      "Warning: GymBullet failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'd4rl_content'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mujoco_py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-08196b98cbee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictlist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Teachable/demo/teachable/scripts/train_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbabyai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miclr19_levels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbabyai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvdist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnvDist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Teachable/demo/teachable/envs/babyai/levels/envdist.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbabyai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miclr19_levels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSerializable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md4rl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md4rl_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocomotion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md4rl_envs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPointMassEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAntEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_envs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPointMassEnvSimple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDummyDiscrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Teachable/demo/teachable/envs/d4rl/d4rl_content/locomotion/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md4rl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md4rl_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocomotion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md4rl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md4rl_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocomotion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmaze_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n",
      "\u001b[0;32m~/Documents/Teachable/demo/teachable/envs/d4rl/d4rl_content/locomotion/ant.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmujoco_py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mujoco_py'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "%matplotlib tk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from scripts.train_model import create_policy\n",
    "from utils.dictlist import DictList\n",
    "\n",
    "from envs.babyai.utils.buffer import Buffer\n",
    "from envs.babyai.bot import OBJ_TYPES\n",
    "from gym_minigrid.minigrid import TILE_PIXELS, Key, Ball, Box, Door, Wall, COLOR_NAMES\n",
    "import numpy as np\n",
    "from envs.babyai.utils.obs_preprocessor import make_obs_preprocessor\n",
    "from utils.utils import set_seed\n",
    "import time\n",
    "import pickle as pkl\n",
    "import uuid\n",
    "\n",
    "# agent_x = 255\n",
    "# agent_y = 250  # TODO: set this!!!! Also think about whether this changes our HILL results\n",
    "\n",
    "# Works for L0\n",
    "AGENT_X = 248\n",
    "AGENT_Y = 252\n",
    "D4RL_TILE_PIXELS = 75 # Works for L0\n",
    "\n",
    "# # WORKS FOR L2\n",
    "AGENT_X = 202\n",
    "AGENT_Y = 296\n",
    "D4RL_TILE_PIXELS = 49#64 # WORKS for L2\n",
    "\n",
    "class HumanFeedback:\n",
    "    def __init__(self, env_type='Ant', collect_type='Advice', save_path=None):\n",
    "        class Args:\n",
    "            def __init__(self):\n",
    "                if env_type == 'BabyAI':\n",
    "                    self.feedback_type = 'OSREasy'\n",
    "                    self.env_type = 'babyai'\n",
    "                    self.env = 49\n",
    "                    self.skip = 1\n",
    "                    self.model = 'saved_models/babyai_offset_advice'\n",
    "                elif env_type == 'Ant':\n",
    "                    self.feedback_type = 'OffsetWaypoint'\n",
    "                    self.env_type = 'ant'\n",
    "                    self.env = 2\n",
    "                    self.skip = 5  # TODO: what value???\n",
    "                    raise NotImplementedError()\n",
    "                    self.model = None # TODO: load model\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                self.no_save = save_path is None\n",
    "                self.advance = 'scroll'\n",
    "                self.num_trajs = 100000\n",
    "                self.seed = 1\n",
    "                self.save_path = str(uuid.uuid4()) if save_path is None else save_path\n",
    "                self.successful_only = False\n",
    "                self.demos = collect_type == 'Demos'\n",
    "                self.base_save_name = self.save_path\n",
    "#                 self.save_path = 'TEMP_buffer' if save_path is None else save_path + '_buffer'        \n",
    "            \n",
    "        # Load model\n",
    "        self.args = Args()\n",
    "        print(\"strating up\")\n",
    "        self.policy, self.env, _ = self.load_policy(self.args.model)\n",
    "        # Load env\n",
    "        self.env.set_level_distribution(self.args.env)\n",
    "        # Create buffer\n",
    "        save_path = pathlib.Path(self.args.save_path)\n",
    "        self.save_path = save_path\n",
    "        if not save_path.exists():\n",
    "            save_path.mkdir()\n",
    "        self.buffer = Buffer(save_path, self.args.num_trajs, val_prob=.1, successful_only=self.args.successful_only)\n",
    "        self.teacher_null_dict = self.env.teacher.null_feedback()\n",
    "        self.teacher_dict = {k: k == self.args.feedback_type for k in self.teacher_null_dict.keys()}\n",
    "        # Create window\n",
    "        self.window = plt.figure(figsize=(10,10))\n",
    "        self.window.canvas.mpl_connect('key_press_event', self.key_handler)\n",
    "        self.window.canvas.mpl_connect('button_press_event', self.onclick)\n",
    "        self.window.canvas.mpl_connect('scroll_event', self.on_scroll)\n",
    "        self.num_trajs = 0\n",
    "        self.obs = None\n",
    "        self.obs_list = []\n",
    "        self.action_list = []\n",
    "        self.action_probs = []\n",
    "        self.teacher_action = []\n",
    "        self.full_done = []\n",
    "        self.advice_count = []\n",
    "        self.advance_count = 0\n",
    "        self.current_feedback_type = self.args.feedback_type\n",
    "        self.feedback_indicator = 0\n",
    "        self.steps_since_feedback = 0\n",
    "        self.last = None\n",
    "        try:\n",
    "            self.advance_count = int(self.args.advance)\n",
    "        except:\n",
    "            pass\n",
    "        self.num_frames = 1\n",
    "        self.num_correct = 1\n",
    "        self.ready = False\n",
    "        self.collecting_val = False\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    def redraw(self, img):\n",
    "        vis_mask = self.env.oracle[self.args.feedback_type].vis_mask\n",
    "        img = self.env.render('rgb_array', tile_size=32, full_vis_mask=vis_mask, highlight=False)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "    def reset(self):\n",
    "        self.obs_list = []\n",
    "        self.action_list = []\n",
    "        self.action_probs = []\n",
    "        self.teacher_action = []\n",
    "        self.full_done = []\n",
    "        self.advice_count = []\n",
    "        self.times = []\n",
    "        self.timesteps = []\n",
    "        self.timestep_counter = 0\n",
    "        self.start_time = time.time()\n",
    "        self.env.set_task()\n",
    "        self.obs = self.env.reset()\n",
    "#         self.decode_feedback(self.obs[self.args.feedback_type], preprocessed=True, tag='orig')\n",
    "        self.last_feedback = self.obs[self.args.feedback_type] * 0\n",
    "        self.clear_feedback()\n",
    "        title_str = f\"Trajectory {self.num_trajs}, frame {self.num_frames}, Last: {self.last}\"\n",
    "        if self.collecting_val:\n",
    "            title_str += ' (validation)'\n",
    "        plt.title(title_str)\n",
    "        if hasattr(self.env, 'mission'):\n",
    "            plt.title(self.env.mission)\n",
    "        self.redraw(self.obs)\n",
    "        self.ready = True\n",
    "\n",
    "    def load_policy(self, path):\n",
    "        path = os.path.join(os.getcwd(), path)\n",
    "        exp_path = os.path.join(path, 'latest.pkl')\n",
    "        exp_data = joblib.load(exp_path)\n",
    "        obs_preprocessor = make_obs_preprocessor([self.args.feedback_type])\n",
    "        env = exp_data['env']\n",
    "        args = exp_data['args']\n",
    "        policy = create_policy(path, self.args.feedback_type, env, args, obs_preprocessor)\n",
    "        set_seed(self.args.seed)\n",
    "        env.seed(self.args.seed)\n",
    "        return policy, env, args\n",
    "\n",
    "    def clear_feedback(self):\n",
    "        return # TODO: add back if we want to auto-swap-in no teacher\n",
    "        empty_feedback = self.env.teacher.empty_feedback()\n",
    "        self.obs.update(empty_feedback)\n",
    "        self.current_feedback_type = 'none'\n",
    "\n",
    "    def step(self, action=None, demo=False):\n",
    "        if not self.ready:\n",
    "            return\n",
    "        for i in range(self.args.skip):\n",
    "            self.num_frames += 1\n",
    "            if not demo:\n",
    "                self.preprocess_obs()\n",
    "#                 self.decode_feedback(self.obs[self.args.feedback_type], preprocessed=True, tag=\"human-p\")\n",
    "            self.feedback_indicator += 1\n",
    "            if action is None:\n",
    "                self.policy.eval()\n",
    "                action, agent_info = self.policy.get_actions([self.obs])\n",
    "            new_obs, reward, done, info = self.env.step(action)\n",
    "            self.advice_count.append(1 if self.steps_since_feedback == 0 else 0)\n",
    "            self.steps_since_feedback += 1\n",
    "            self.timestep_counter += 1\n",
    "            self.obs_list.append(self.obs)\n",
    "            self.action_list.append(action)\n",
    "            self.teacher_action.append(0)\n",
    "            self.full_done.append(done)\n",
    "            self.times.append(time.time() - self.start_time)\n",
    "            self.timesteps.append(self.timestep_counter)\n",
    "            self.obs = new_obs\n",
    "            action = None\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "#         self.decode_feedback(new_obs[self.args.feedback_type], preprocessed=True, tag=' orig')\n",
    "\n",
    "\n",
    "        if done:\n",
    "            self.last = 'success' if info['success'] else 'timed out'\n",
    "            self.end_trajectory(self.obs)\n",
    "        else:\n",
    "            self.redraw(self.obs)\n",
    "\n",
    "    def preprocess_obs(self):\n",
    "        if not self.args.feedback_type == 'PreActionAdvice':\n",
    "            self.set_feedback()\n",
    "        feedback_obs = self.obs[self.args.feedback_type]\n",
    "        if self.args.feedback_type == 'OffsetWaypoint':\n",
    "            feedback_obs[:] -= self.env.get_pos()\n",
    "        if self.args.feedback_type in ['SubgoalCorrections', 'SubgoalSimple']:\n",
    "            # Add agent pos and dir\n",
    "            feedback_obs[-1] = self.env.agent_dir / 3\n",
    "            feedback_obs[-3: -1] = (self.env.agent_pos - 12) / 12\n",
    "            # Change target to offset\n",
    "            feedback_obs[-5: -3] = (feedback_obs[-5: -3] - self.env.agent_pos) / 10\n",
    "        elif self.args.feedback_type in ['OFFIO', 'OFFSparse', 'OFFSparseRandom', 'OSRPeriodicImplicit', 'OSREasy']:\n",
    "            # Add feedback indicator\n",
    "            feedback_freq = self.env.teacher.teachers[self.args.feedback_type].feedback_frequency  # TODO: add SSF\n",
    "            feedback_indicator = np.zeros(feedback_freq)\n",
    "            steps_since_feedback = min(self.steps_since_feedback, feedback_freq - 1)\n",
    "            feedback_indicator[steps_since_feedback] = 1\n",
    "            feedback_obs[-feedback_freq:] = feedback_indicator\n",
    "            # Turn the absolute coordinate into an offset\n",
    "            if steps_since_feedback == 0 or self.args.feedback_type in ['OSREasy', 'OSRPeriodicImplicit']:\n",
    "                feedback_obs[1:3] = feedback_obs[1:3] - self.env.agent_pos\n",
    "            # Add agent pos and dir\n",
    "            if steps_since_feedback == 0 or self.args.feedback_type in ['OSREasy', 'OSRPeriodicImplicit', 'OFFSparseRandom']:\n",
    "                feedback_obs[-feedback_freq - 1] = self.env.agent_dir / 3\n",
    "                feedback_obs[-feedback_freq - 3: -feedback_freq - 1] = (self.env.agent_pos - 12) / 12\n",
    "            else:\n",
    "                feedback_obs[-feedback_freq - 1] = -1\n",
    "                feedback_obs[-feedback_freq - 3: -feedback_freq - 1] = np.array([-1, -1])\n",
    "\n",
    "    def onclick(self, event):\n",
    "        try:\n",
    "            ix, iy = event.xdata, event.ydata\n",
    "            pixels = TILE_PIXELS if self.args.env_type == 'babyai' else D4RL_TILE_PIXELS\n",
    "            coord_width = ix / pixels\n",
    "            coord_height = iy / pixels\n",
    "\n",
    "            if self.args.env_type == 'd4rl':\n",
    "                coord_x = (ix - AGENT_X) / D4RL_TILE_PIXELS\n",
    "                coord_y = (iy - AGENT_Y) / D4RL_TILE_PIXELS\n",
    "                if self.args.feedback_type == 'Direction':\n",
    "                    dir = np.array([coord_x, coord_y])\n",
    "                    self.set_feedback(dir)\n",
    "                    return\n",
    "                elif self.args.feedback_type in ['Waypoint', 'OffsetWaypoint']:\n",
    "                    if event.button == 1:  # left click, normal waypoint\n",
    "                        x = round(coord_x)\n",
    "                        y = round(coord_y)\n",
    "                    elif event.button == 3:  # right click, goal\n",
    "                        x = coord_x\n",
    "                        y = coord_y\n",
    "                    self.set_feedback(np.array([-y, x], dtype=np.float64))\n",
    "                    return\n",
    "\n",
    "            x = int(coord_width)\n",
    "            y = int(coord_height)\n",
    "            offset_x = x - self.env.agent_pos[0]\n",
    "            offset_y = y - self.env.agent_pos[1]\n",
    "            # choose the direction based on which side of the cell we're closest to\n",
    "            left_diff = coord_width - x\n",
    "            right_diff = x + 1 - coord_width\n",
    "            top_diff = coord_height - y\n",
    "            bottom_diff = y + 1 - coord_height\n",
    "            agent_dir = np.argmin([top_diff, right_diff, bottom_diff, left_diff])\n",
    "            agent_diff = agent_dir - self.env.agent_dir\n",
    "\n",
    "            if self.args.feedback_type == 'OFFIO':\n",
    "                coords = np.zeros(4)\n",
    "                coords[0] = offset_x\n",
    "                coords[1] = offset_y\n",
    "                if agent_diff == 3:\n",
    "                    agent_diff = -1\n",
    "                elif agent_diff == -3:\n",
    "                    agent_diff = 1\n",
    "                coords[2] = agent_diff\n",
    "                coords[3] = self.env.agent_dir\n",
    "                self.set_feedback(coords)\n",
    "            elif self.args.feedback_type in ['OSRPeriodicImplicit', 'OSREasy']:\n",
    "                is_obj = 1 if type(self.env.grid.get(x, y)) in [Key, Ball, Box, Door] else 0\n",
    "                coords = np.zeros(3 + 3 + self.env.teacher.teachers[self.args.feedback_type].feedback_frequency)\n",
    "                coords[0] = is_obj\n",
    "                coords[1] = x\n",
    "                coords[2] = y\n",
    "                self.set_feedback(coords)\n",
    "            elif self.args.feedback_type in ['OFFSparse', 'OFFSparseRandom']:\n",
    "                is_obj = 1 if type(self.env.grid.get(x, y)) in [Key, Ball, Box, Door] else 0\n",
    "                coords = np.zeros(3 + 3 + self.env.teacher.teachers[self.args.feedback_type].feedback_frequency)\n",
    "                coords[0] = is_obj\n",
    "                coords[1] = offset_x\n",
    "                coords[2] = offset_y\n",
    "                # self.decode_offset(coords, preprocessed=False)\n",
    "                self.set_feedback(coords)\n",
    "            elif self.args.feedback_type in ['SubgoalCorrections', 'SubgoalSimple']:\n",
    "                obj = self.env.grid.get(x, y)\n",
    "                subgoal_names = ['OpenSubgoal',\n",
    "                                 'DropSubgoal',\n",
    "                                 'PickupSubgoal',\n",
    "                                 'GoNextToSubgoal']\n",
    "                subgoal_idx_all = np.zeros(len(subgoal_names) + 1\n",
    "                                           + len(COLOR_NAMES) + 1\n",
    "                                           + len(OBJ_TYPES) + 1\n",
    "                                           + 2\n",
    "                                           + 3)\n",
    "                if type(obj) is Door:\n",
    "                    if obj.is_open or event.button == 1:\n",
    "                        subgoal_name = 'GoNextToSubgoal'\n",
    "                    else:\n",
    "                        subgoal_name = 'OpenSubgoal'\n",
    "                elif type(obj) in [Key, Box, Ball]:\n",
    "                    if event.button == 1:  # left click, GoTo\n",
    "                        subgoal_name = 'GoNextToSubgoal'\n",
    "                    elif self.env.carrying:\n",
    "                        subgoal_name = 'DropSubgoal'\n",
    "                    else:\n",
    "                        subgoal_name = 'PickupSubgoal'\n",
    "                elif obj is None or type(obj) == Wall:\n",
    "                    if event.button == 1:  # left click, GoTo\n",
    "                        subgoal_name = 'GoNextToSubgoal'\n",
    "                    elif event.button == 3:  # right click, PickUp\n",
    "                        subgoal_name = 'DropSubgoal'\n",
    "                    else:\n",
    "                        print(\"huh2?\", event.button)\n",
    "                else:\n",
    "                    print(x, y)\n",
    "                    print(f\"OBJ is {type(obj)}; invalid subgoal\")\n",
    "                    print(f\"OBJ is {obj is None}; invalid subgoal\")\n",
    "                    return\n",
    "                subgoal_val = np.array([x, y])\n",
    "                if type(obj) in [Box, Ball, Key, Door]:\n",
    "                    color_idx = COLOR_NAMES.index(obj.color)\n",
    "                    type_idx = OBJ_TYPES.index(obj.type)\n",
    "                else:\n",
    "                    color_idx = len(COLOR_NAMES)\n",
    "                    type_idx = len(OBJ_TYPES)\n",
    "\n",
    "                # Index the subgoal type\n",
    "                subgoal_idx_all[subgoal_names.index(subgoal_name)] = 1.0\n",
    "                curr_idx = len(subgoal_names) + 1\n",
    "                # Index target object color\n",
    "                subgoal_idx_all[curr_idx + color_idx] = 1.0\n",
    "                curr_idx += len(COLOR_NAMES) + 1\n",
    "                # Index target object name\n",
    "                subgoal_idx_all[curr_idx + type_idx] = 1.0\n",
    "                curr_idx += len(OBJ_TYPES) + 1\n",
    "                # Index the target coordinate\n",
    "                subgoal_idx_all[curr_idx:curr_idx + 2] = subgoal_val\n",
    "                curr_idx += 2\n",
    "                # Index current agent position\n",
    "                subgoal_idx_all[curr_idx: curr_idx + 2] = (self.env.agent_pos - 12) / 12\n",
    "                curr_idx += 2\n",
    "                # Index current agent orientation\n",
    "                subgoal_idx_all[curr_idx] = self.env.agent_dir / 3\n",
    "                self.set_feedback(subgoal_idx_all)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"invalid coordinate\", e)\n",
    "\n",
    "    def add_feedback_indicator(self):\n",
    "        if self.args.feedback_type in ['OFFIO', 'OFFSparseRandom', 'OSRPeriodicImplicit', 'OFFSR', 'OSREasy']:\n",
    "            indicator = self.env.teacher.teachers[self.args.feedback_type].get_last_feedback_indicator()\n",
    "            self.obs[self.args.feedback_type] = np.concatenate([self.obs[self.args.feedback_type], indicator])\n",
    "\n",
    "    def decode_feedback(self, feedback, preprocessed=True, tag=''):  # TODO: eventually delete this\n",
    "        if self.args.feedback_type == 'Direction':\n",
    "            self.decode_direction(feedback.copy(), preprocessed, tag)\n",
    "        elif self.args.feedback_type == 'Cardinal':\n",
    "            self.decode_cardinal(feedback.copy(), preprocessed, tag)\n",
    "        elif self.args.feedback_type  == 'Waypoint':\n",
    "            self.decode_waypoint(feedback.copy(), preprocessed, tag)\n",
    "        elif self.args.feedback_type == 'OffsetWaypoint':\n",
    "            self.decode_offsetwaypoint(feedback.copy(), preprocessed, tag)\n",
    "        if self.args.feedback_type in ['OFFIO', 'OFFSparseRandom', 'OSRPeriodicImplicit', 'OFFSR', 'OSREasy']:\n",
    "            self.decode_offset(feedback.copy(), preprocessed, tag)\n",
    "        elif self.args.feedback_type in ['SubgoalCorrections', 'SubgoalSimple']:\n",
    "            self.decode_subgoal(feedback.copy(), preprocessed, tag)\n",
    "\n",
    "    def decode_direction(self, feedback, _, tag):\n",
    "        print(f\"{tag} Head in direction {feedback}\")\n",
    "\n",
    "    def decode_cardinal(self, feedback, _, tag):\n",
    "        index = np.argmax(feedback)\n",
    "        dir = ['left', 'up', 'right', 'down'][index]\n",
    "        print(f\"{tag} Head in direction {dir}\")\n",
    "\n",
    "    def decode_offsetwaypoint(self, feedback, preprocessed, tag):\n",
    "        if not preprocessed:\n",
    "            # TODO: okay??\n",
    "            og = feedback.copy()\n",
    "            feedback = feedback - self.env.get_pos()\n",
    "        og = None\n",
    "        print(f\"{tag} OffsetWaypoint: {feedback}, {og}\")\n",
    "\n",
    "    def decode_waypoint(self, feedback, _, tag):\n",
    "        print(f\"{tag} Waypoint: {feedback * 15}\")\n",
    "\n",
    "    def decode_offset(self, offset, preprocessed=True, tag=\"\"):  # TODO: currently only handles sparse\n",
    "        first = offset[0]\n",
    "        coords_offset = offset[1:3]\n",
    "        start_str = \"Using an obj at \" if first else \"Going to\"\n",
    "        if preprocessed:\n",
    "            agent_pos = offset[3: 5] * 12 + 12\n",
    "            agent_dir = offset[5] * 3\n",
    "            if agent_dir < 0:\n",
    "                agent_dir = offset[5]\n",
    "                agent_pos = offset[3: 5]\n",
    "            timesteps_ago = np.argmax(offset[6:])\n",
    "        else:\n",
    "            agent_pos = agent_dir = timesteps_ago = -1\n",
    "\n",
    "            coords_offset -= self.env.agent_pos\n",
    "\n",
    "        print(f\"{tag} {start_str} {coords_offset}, {timesteps_ago} timesteps ago\"\n",
    "              f\" pos {agent_pos}, dir {agent_dir}\")\n",
    "\n",
    "    def decode_subgoal(self, subgoal, preprocessed=True, tag=''):\n",
    "        # Subgoal Name\n",
    "        subgoal_names = ['OpenSubgoal',\n",
    "                         'DropSubgoal',\n",
    "                         'PickupSubgoal',\n",
    "                         'GoNextToSubgoal']\n",
    "        subgoal_name = subgoal_names[np.argmax(subgoal[:len(subgoal_names)]).item()]\n",
    "        curr_idx = len(subgoal_names) + 1\n",
    "        # Obj color\n",
    "        obj_color = (COLOR_NAMES + ['none'])[np.argmax(subgoal[curr_idx: curr_idx + len(COLOR_NAMES) + 1]).item()]\n",
    "        curr_idx += len(COLOR_NAMES) + 1\n",
    "        # Obj name\n",
    "        obj_type = (OBJ_TYPES + ['none'])[np.argmax(subgoal[curr_idx: curr_idx + len(OBJ_TYPES) + 1]).item()]\n",
    "        curr_idx += len(OBJ_TYPES) + 1\n",
    "        # Target coordinate\n",
    "        coordinate = subgoal[curr_idx: curr_idx + 2]\n",
    "        curr_idx += 2\n",
    "        # Agent pos\n",
    "        agent_pos = subgoal[curr_idx: curr_idx + 2] * 12 + 12\n",
    "        curr_idx += 2\n",
    "        # Agent Dir\n",
    "        agent_dir = subgoal[curr_idx] * 3\n",
    "        if preprocessed:\n",
    "            coordinate = (coordinate * 10) + agent_pos\n",
    "        print(f\"{tag} Name: {subgoal_name}, Coord: {coordinate}, \"\n",
    "               f\"obj {obj_color} {obj_type}, pos {agent_pos}, dir {agent_dir}\")\n",
    "\n",
    "    def on_scroll(self, event):\n",
    "        if self.args.advance == 'scroll':\n",
    "            self.step()\n",
    "\n",
    "    def set_feedback(self, feedback=None, demo=False):\n",
    "        self.ready = True\n",
    "        if self.args.demos and demo:\n",
    "            action = np.array([int(feedback)])\n",
    "            self.step(action, demo)\n",
    "            return\n",
    "        if feedback is None:\n",
    "            feedback = self.last_feedback\n",
    "        else:\n",
    "            self.steps_since_feedback = 0\n",
    "            self.obs['gave_' + self.args.feedback_type] = 1.0\n",
    "        self.last_feedback = feedback.copy()\n",
    "        self.feedback_indicator = 0\n",
    "        self.current_feedback_type = self.args.feedback_type\n",
    "\n",
    "        if self.args.feedback_type == 'PreActionAdvice':\n",
    "            feedback = int(feedback)\n",
    "            assert feedback >= 0\n",
    "            assert feedback <= 7\n",
    "            curr_feedback = np.zeros(8)\n",
    "            curr_feedback[feedback] = 1\n",
    "            self.obs[self.args.feedback_type] = curr_feedback\n",
    "            self.last_feedback = curr_feedback\n",
    "        else:\n",
    "            self.obs[self.args.feedback_type] = feedback\n",
    "        for _ in range(self.advance_count):\n",
    "            self.step()\n",
    "#         self.decode_feedback(self.obs[self.args.feedback_type].copy(), preprocessed=False, tag=\"human-nop\")\n",
    "\n",
    "    def end_trajectory(self, final_obs):\n",
    "        self.num_trajs += 1\n",
    "        self.full_done[-1] = 1\n",
    "        if not self.args.no_save:\n",
    "            # Save buffer\n",
    "            env_infos = {\n",
    "                'advice_count': torch.IntTensor(self.advice_count),\n",
    "                'success': np.array(self.full_done),\n",
    "            }\n",
    "\n",
    "            traj_dict = {\n",
    "                'obs': self.obs_list,\n",
    "                'next_obs': self.obs_list[1:] + [final_obs],\n",
    "                'action': torch.FloatTensor(np.concatenate(self.action_list)).cuda(),\n",
    "                # 'action_probs': self.action_probs,\n",
    "                'teacher_action': torch.FloatTensor(self.teacher_action),\n",
    "                'full_done': torch.FloatTensor(self.full_done),\n",
    "                'env_infos': DictList(env_infos)\n",
    "            }\n",
    "            assert len(traj_dict['teacher_action'].shape) == len(traj_dict['full_done'].shape) == 1\n",
    "            traj = DictList(traj_dict)\n",
    "            print(\"adding buffer\", self.buffer.buffer_path)\n",
    "            self.buffer.add_batch(traj, trim=True, only_val=self.collecting_val)\n",
    "            print(\"counts after adding\", self.buffer.counts_train, self.buffer.counts_val)\n",
    "            path = self.save_path.joinpath('timesteps.pkl')\n",
    "            time_dict = {'timesteps': self.timesteps, 'times': self.times}\n",
    "            print(\"save to file\", path)\n",
    "            with open(path, 'wb') as f:\n",
    "                pkl.dump(time_dict, f)\n",
    "        # Reset\n",
    "        self.reset()\n",
    "\n",
    "    def key_handler(self, event):\n",
    "        print(\"got a key!\", event.key)\n",
    "        demo = self.args.demos\n",
    "        # if event.key == ' ':\n",
    "        #     self.step()\n",
    "        #     return\n",
    "        if event.key == 'v':\n",
    "            self.collecting_val = not self.collecting_val\n",
    "        if event.key == 'r':\n",
    "            print(\"ending traj\")\n",
    "            self.last = 'manual reset'\n",
    "            self.end_trajectory(self.obs)\n",
    "            return\n",
    "        if event.key == 'c':\n",
    "            self.step()\n",
    "        if self.args.feedback_type == 'Cardinal':\n",
    "            arr = np.zeros(4)\n",
    "            if event.key == 'left':\n",
    "                arr[0] = 1\n",
    "            if event.key == 'right':\n",
    "                arr[2] = 1\n",
    "            if event.key == 'up':\n",
    "                arr[1] = 1\n",
    "            if event.key == 'down':\n",
    "                arr[3] = 1\n",
    "            self.set_feedback(arr, demo=False)\n",
    "            return\n",
    "        elif self.args.env_type == 'babyai' and (self.args.feedback_type == 'PreActionAdvice' or self.args.demos):\n",
    "            actions = self.env._wrapped_env.Actions\n",
    "            if event.key == 'left':\n",
    "                print(\"FEEDBACK TYPES\", type(actions), type(actions.left))\n",
    "                self.set_feedback(actions.left, demo=demo)\n",
    "                return\n",
    "            if event.key == 'right':\n",
    "                self.set_feedback(actions.right, demo=demo)\n",
    "                return\n",
    "            if event.key == 'up':\n",
    "                self.set_feedback(actions.forward, demo=demo)\n",
    "                return\n",
    "\n",
    "            # Spacebar\n",
    "            if event.key == ' ':\n",
    "                self.set_feedback(actions.toggle, demo=demo)\n",
    "                return\n",
    "            if event.key == 'pageup':\n",
    "                self.set_feedback(actions.pickup, demo=demo)\n",
    "                return\n",
    "            if event.key == 'pagedown':\n",
    "                self.set_feedback(actions.drop, demo=demo)\n",
    "                return\n",
    "        else:\n",
    "            raise print(\"Invalid key\", event.key)\n",
    "        print('pressed', event.key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selections\n",
    "\n",
    "(CHOOSE ONCE; RE-RUN IF NEEDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env_type = 'BabyAI'\n",
    "collect_type = 'Advice'\n",
    "save_path = 'another_path'\n",
    "\n",
    "env_button = widgets.ToggleButtons(\n",
    "    options=['Ant', 'BabyAI'],\n",
    "    description='Environment',\n",
    "    disabled=False,\n",
    "    button_style=''\n",
    ")\n",
    "def update_env(d):\n",
    "    global env_type\n",
    "    env_type = d['new']\n",
    "env_button.observe(update_env, names='value')\n",
    "\n",
    "collect_button = widgets.ToggleButtons(\n",
    "    options=['Advice', 'Demos', 'Precollected'],\n",
    "    description='Collect Mode',\n",
    "    disabled=False,\n",
    "    button_style=''\n",
    ")\n",
    "def update_collect(d):\n",
    "    global collect_type\n",
    "    collect_type = d['new']\n",
    "collect_button.observe(update_collect, names='value')\n",
    "\n",
    "save_button = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Save Name (leave blank for no saving)',\n",
    "    description='Save Name:',\n",
    "    disabled=False\n",
    ")\n",
    "def update_save(d):\n",
    "    global save_path\n",
    "    save_path = None if d['new'] == '' else d['new']\n",
    "save_button.observe(update_save, names='value')\n",
    "\n",
    "\n",
    "items = [env_button, collect_button, save_button]\n",
    "widgets.Box(items)\n",
    "\n",
    "human_collector = HumanFeedback(env_type=env_type, collect_type=collect_type, save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection\n",
    "\n",
    "TODO: INSERT DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Here, we train a policy using the buffer of collected trajectories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scripts.train_model import *\n",
    "from scripts.arguments import ArgumentParser\n",
    "import sys\n",
    "sys.argv = sys.argv[:1]\n",
    "parser = ArgumentParser()\n",
    "args = parser.parse_args()\n",
    "args.prefix = save_path\n",
    "args.env = 'babyai'\n",
    "args.level = 49\n",
    "args.buffer_path = human_collector.args.base_save_name\n",
    "args.distill_teacher = 'none'\n",
    "args.num_rollouts = 1\n",
    "\n",
    "run_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize\n",
    "\n",
    "Play video saved during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(data=\"/home/olivia/Documqents/Teachable/demo/teachable/logs/another_path/Policyanother_path-49_checkpoint1/vid.avi\",\n",
    "     embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(filename=pathlib.Path(\"vid.avi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video alt=\"test\" controls>\n",
    "        <source src=\"/home/olivia/Documents/Teachable/demo/teachable/logs/another_path/Policyanother_path-49_checkpoint1/vid.avi\" type=\"video/avi\">\n",
    "    </video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
